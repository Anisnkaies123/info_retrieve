{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC of model finetuning using AISG FAQ data\n",
    "Note: this is not a rigorous proof of the finetuning abilities, it merely shows that we are able to overfit to one dataset. The main purpose is to build and test the finetuning code using tensorflow.  \n",
    "Tested with just minimizing cosine loss. This kind of works, but having a triplet loss might be better.  \n",
    "Triplet takes many more epochs before it gets the same accuracy as just minimizing cosine loss, but I think it should be more robust. Will have to try both on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from src.utils import read_txt, split_txt, aiap_qna_quickscore\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1106 07:07:14.476074 140634671175424 deprecation.py:323] From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 07:07:29.406564 140634671175424 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 07:07:35.827173 140634671175424 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 07:07:42.667761 140634671175424 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py:331: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 07:07:44.159590 140634671175424 deprecation.py:323] From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py:331: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 07:07:44.298229 140634671175424 deprecation.py:323] From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n"
     ]
    }
   ],
   "source": [
    "from src.model import GoldenRetriever\n",
    "model=GoldenRetriever(loss='triplet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiap_qa, aiap_context = split_txt(read_txt('../data/aiap.txt'), qa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q1. WHAT SORT OF CANDIDATES ARE YOU LOOKING FOR?', 'Q2. WHAT WILL BE COVERED IN THE PROGRAMME?', 'Q3. DO I HAVE TO PAY?', 'Q4. WHAT IS THE OUTCOME OF THIS PROGRAMME?', 'Q5. WILL I GET A JOB AFTER THE PROGRAMME?', 'Q6. WILL THERE BE A NEXT ROUND OF APPLICATION?', 'Q7. DO I HAVE TO GIVE UP MY CURRENT JOB TO JOIN THE  PROGRAMME?', 'Q8. WHAT IF I DECIDED TO DROP OUT OF THE PROGRAMME?', 'Q9. WILL I GET SOME SORT OF CERTIFICATE TO SHOW THAT I PARTICIPATED IN THE AIAP?', 'Q10. WHAT ARE THE AI JOBS AND ROLES I CAN CONSIDER AFTER COMPLETING THE TRAINING PROGRAMME?']\n"
     ]
    }
   ],
   "source": [
    "print(aiap_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0112743 ,  0.04894138, -0.06490619, ...,  0.09330797,\n",
       "         0.01958819, -0.02537908],\n",
       "       [ 0.04272488,  0.0623336 ,  0.02158852, ...,  0.06216078,\n",
       "         0.00950298, -0.03111232],\n",
       "       [-0.05566482,  0.02913201,  0.0255424 , ...,  0.0459285 ,\n",
       "         0.00670882, -0.07619023],\n",
       "       ...,\n",
       "       [-0.01923553, -0.06181138,  0.01505679, ...,  0.07817681,\n",
       "         0.02878742, -0.07518731],\n",
       "       [-0.014769  , -0.05544962,  0.09171879, ...,  0.0126055 ,\n",
       "        -0.02055403, -0.05686105],\n",
       "       [ 0.05459761,  0.03379358,  0.01586364, ...,  0.03275432,\n",
       "         0.04136325,  0.03180375]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(aiap_qa, type='query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5\n",
      "1 0.6\n",
      "2 0.6\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    print(k, aiap_qna_quickscore(aiap_context, model.predict(aiap_qa, type='response'), aiap_qa, model, k+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /data/home/lik/info_retrieve/google_use_qa_tuned/variables-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 07:08:42.459116 140634671175424 saver.py:1270] Restoring parameters from /data/home/lik/info_retrieve/google_use_qa_tuned/variables-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model checkpoint restored!\n"
     ]
    }
   ],
   "source": [
    "model.restore('/data/home/lik/info_retrieve/google_use_qa_tuned/variables-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8\n",
      "1 1.0\n",
      "2 1.0\n",
      "3 1.0\n",
      "4 1.0\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    print(k, aiap_qna_quickscore(aiap_context, model.predict(aiap_qa, type='response'), aiap_qa, model, k+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune model\n",
    "overfitting on default questions will happen between 10-15 epoch on cosine loss. Model checkpointed with 15 epoch of training with shuffled mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "aiap_context_trim=[' '.join(x.split(' ')[1:]) for x in aiap_context]\n",
    "aiap_context_trim\n",
    "\n",
    "def shuffle_mistakes():\n",
    "    aiap_ans_neg = aiap_qa.copy()\n",
    "    shuffle_ind = [ii for ii in range(10)]\n",
    "    random.shuffle(shuffle_ind)\n",
    "    aiap_ans_neg=[aiap_ans_neg[ii] for ii in shuffle_ind]\n",
    "    return aiap_ans_neg\n",
    "aiap_ans_neg = shuffle_mistakes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.015765548\n",
      "0.29999995\n",
      "0.3\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.23655546\n",
      "0.30000007\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3\n",
      "0.0\n",
      "0.0\n",
      "0.3\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3\n",
      "0.0\n",
      "0.0\n",
      "0.088243246\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.06774145\n",
      "0.0\n",
      "0.0\n",
      "0.00056535006\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    aiap_ans_neg = shuffle_mistakes()\n",
    "    for answer, question, neg_qn in zip(aiap_qa, aiap_context_trim, aiap_ans_neg):\n",
    "#         print(answer, question)\n",
    "        print(model.finetune([question], [answer], [answer], [neg_qn], [neg_qn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "1 1.0\n",
      "2 1.0\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    print(k, aiap_qna_quickscore(aiap_context_trim, model.predict(aiap_qa), aiap_qa, model, k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.export(savepath='../google_use_qa_tuned/variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=QnaEncoderModel(loss='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 epoch 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning on toy dataset works! Now to try for insurance dataset\n",
    "This is more rigorous, cause I will be testing on unseen data.\n",
    "## First load the test framework for qna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import question_cleaner, display_qn_and_ans, aiap_qna, ranker, scorer\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2000, removed:677, remainder:1323\n"
     ]
    }
   ],
   "source": [
    "datapath=Path('../data')\n",
    "df_query = pd.read_csv(datapath/'insuranceQA/V2/InsuranceQA.question.anslabel.raw.500.pool.solr.train.encoded', delimiter='\\t', header=None)\n",
    "df_doc = pd.read_csv(datapath/'insuranceQA/V2/InsuranceQA.label2answer.raw.encoded', delimiter='\\t', header=None)\n",
    "df_ind2word = pd.read_csv(datapath/'insuranceQA/V2/vocabulary', sep='\\t', header=None, quotechar='', quoting=3, keep_default_na=False)\n",
    "dict_ind2word = pd.Series(df_ind2word[1].values,index=df_ind2word[0].values).to_dict()\n",
    "\n",
    "df_test = pd.read_csv(datapath/'insuranceQA/V2/InsuranceQA.question.anslabel.raw.100.pool.solr.test.encoded', delimiter='\\t', header=None)\n",
    "df_test=question_cleaner(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:12889, removed:2498, remainder:10391\n"
     ]
    }
   ],
   "source": [
    "df_query=question_cleaner(df_query)\n",
    "df_doc=df_doc.set_index(0)\n",
    "\n",
    "def func(row):\n",
    "    kb=[int(xx) for xx in (row[3]).split(' ')]\n",
    "    gt = [int(xx) for xx in (row[2]).split(' ')]\n",
    "    return random.sample([xx for xx in kb if xx not in gt], 100)\n",
    "df_query['neg_samples']=df_query.apply(lambda x: func(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>neg_samples</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>life-insurance</td>\n",
       "      <td>idx_3019 idx_16371 idx_5499 idx_448 idx_136 id...</td>\n",
       "      <td>26354</td>\n",
       "      <td>13324 23395 7870 15080 27181 25052 26694 568 2...</td>\n",
       "      <td>[127, 21311, 22635, 11029, 4920, 2125, 6970, 1...</td>\n",
       "      <td>Can Creditors Take Life Insurance After Death?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1      2  \\\n",
       "1  life-insurance  idx_3019 idx_16371 idx_5499 idx_448 idx_136 id...  26354   \n",
       "\n",
       "                                                   3  \\\n",
       "1  13324 23395 7870 15080 27181 25052 26694 568 2...   \n",
       "\n",
       "                                         neg_samples  \\\n",
       "1  [127, 21311, 22635, 11029, 4920, 2125, 6970, 1...   \n",
       "\n",
       "                                             text  \n",
       "1  Can Creditors Take Life Insurance After Death?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medicare-insurance</td>\n",
       "      <td>idx_2363 idx_467 idx_8080 idx_31 idx_9966 idx_...</td>\n",
       "      <td>9128</td>\n",
       "      <td>9128 13322 21601 21471 6442 5412 24861 23536 2...</td>\n",
       "      <td>Will Medicare Pay For Smoking Cessation?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "4  medicare-insurance  idx_2363 idx_467 idx_8080 idx_31 idx_9966 idx_...   \n",
       "\n",
       "      2                                                  3  \\\n",
       "4  9128  9128 13322 21601 21471 6442 5412 24861 23536 2...   \n",
       "\n",
       "                                       text  \n",
       "4  Will Medicare Pay For Smoking Cessation?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_...</td>\n",
       "      <td>Coverage follows the car. Example 1: If you we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1  \\\n",
       "0                                                      \n",
       "1  idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_...   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  Coverage follows the car. Example 1: If you we...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def wordifier(tokes):\n",
    "    return ' '.join([dict_ind2word[ind] for ind in tokes.strip().split(' ')])\n",
    "df_doc['text']=df_doc.apply(lambda x: wordifier(x[1]), axis=1)\n",
    "df_query['text']=df_query.apply(lambda x: wordifier(x[1]), axis=1)\n",
    "df_test['text']=df_test.apply(lambda x: wordifier(x[1]), axis=1)\n",
    "display(df_query.head(1))\n",
    "display(df_test.head(1))\n",
    "display(df_doc.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_wrong(question, all_wrong_ans, model, k=1):\n",
    "    wrong_answer_array=model.predict(all_wrong_ans, type='response')\n",
    "    sorted_ans, sortargs, similarity_score=aiap_qna(question, wrong_answer_array, all_wrong_ans, model, k=50)\n",
    "    return sorted_ans[0]\n",
    "\n",
    "def generate_triplets(df_query):\n",
    "    answers=[]\n",
    "    questions=[]\n",
    "    wrong_answers=[]\n",
    "    for ii, row in df_query.iterrows():\n",
    "        all_correct_ans = [int(xx) for xx in row[2].split(' ')]\n",
    "        all_wrong_ans = df_doc.loc[row['neg_samples'], 'text'].tolist()\n",
    "        for ans in all_correct_ans:\n",
    "            answers.append(df_doc.loc[ans, 'text'])\n",
    "            questions.append(row['text'])\n",
    "            wrong_answers.append(get_hard_wrong(row['text'], all_wrong_ans, model))\n",
    "    return answers, questions, wrong_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers, questions, wrong_answers=generate_triplets(df_query)\n",
    "# with open(datapath/\"tmp_trainset.pickle\", \"wb\") as f:\n",
    "#     pickle.dump((answers,questions,wrong_answers), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath/\"tmp_trainset.pickle\", \"rb\") as f:\n",
    "    answers,questions,wrong_answers = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(wrong_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.024368823\n",
      "100 0.0042471886\n",
      "200 0.010198474\n",
      "300 0.0\n",
      "400 0.0\n",
      "500 0.0\n",
      "600 0.0\n",
      "700 0.0\n",
      "800 0.012136817\n",
      "900 0.013827622\n",
      "1000 0.0\n",
      "1100 0.0052496195\n",
      "1200 0.0049781203\n",
      "1300 0.0025287867\n",
      "1400 0.0\n",
      "1500 0.0\n",
      "1600 0.0\n",
      "1700 0.0\n",
      "1800 0.0\n",
      "1900 0.0\n",
      "2000 0.0\n",
      "2100 0.0\n",
      "2200 0.0\n",
      "2300 0.0\n",
      "2400 0.0\n",
      "2500 0.001412332\n",
      "2600 0.0\n",
      "2700 0.0\n",
      "2800 0.0\n",
      "2900 0.0\n",
      "3000 0.0\n",
      "3100 0.0\n",
      "3200 0.0009291172\n",
      "3300 0.0\n",
      "3400 0.0\n",
      "3500 0.0\n",
      "3600 0.0\n",
      "3700 0.0\n",
      "3800 0.0\n",
      "3900 0.0\n",
      "4000 0.0\n",
      "4100 0.0\n",
      "4200 0.0\n",
      "4300 0.0\n",
      "4400 0.0\n",
      "4500 0.0\n",
      "4600 0.0\n",
      "4700 0.0\n",
      "4800 0.0\n",
      "4900 0.0\n",
      "5000 0.0\n",
      "5100 0.0\n",
      "5200 0.0\n",
      "5300 0.0\n",
      "5400 0.0\n",
      "5500 0.0\n",
      "5600 0.0\n",
      "5700 0.0\n",
      "5800 0.0\n",
      "5900 0.0\n",
      "6000 0.0\n",
      "6100 0.0\n",
      "6200 0.0\n",
      "6300 0.0\n",
      "6400 0.0\n",
      "6500 0.0\n",
      "6600 0.0\n",
      "6700 0.0\n",
      "6800 0.0\n",
      "6900 0.0\n",
      "7000 0.0\n",
      "7100 0.0\n",
      "7200 0.0\n",
      "7300 0.0\n",
      "7400 0.0\n",
      "7500 0.0\n",
      "7600 0.0\n",
      "7700 0.0\n",
      "7800 0.0\n",
      "7900 0.0\n",
      "8000 0.0\n",
      "8100 0.0\n",
      "8200 0.0\n",
      "8300 0.0\n",
      "8400 0.0\n",
      "8500 0.0\n",
      "8600 0.0\n",
      "8700 0.0\n",
      "8800 0.0\n",
      "8900 0.0\n",
      "9000 0.0\n",
      "9100 0.0\n",
      "9200 0.0\n",
      "9300 0.0\n",
      "9400 0.0\n",
      "9500 0.0\n",
      "9600 0.0\n",
      "9700 0.0\n",
      "9800 0.0\n",
      "9900 0.0\n",
      "10000 0.0\n",
      "10100 0.0\n",
      "10200 0.0\n",
      "10300 0.0\n",
      "10400 0.0\n",
      "10500 0.0\n",
      "10600 0.0\n",
      "10700 0.0\n",
      "10800 0.0\n",
      "10900 0.0\n",
      "11000 0.0\n",
      "11100 0.0\n",
      "11200 0.0\n",
      "11300 0.0\n",
      "11400 0.0\n",
      "11500 0.0\n",
      "11600 0.0\n",
      "11700 0.0\n",
      "11800 0.0\n",
      "11900 0.0\n",
      "12000 0.0\n",
      "12100 0.0\n",
      "12200 0.0\n",
      "12300 0.0\n",
      "12400 0.0\n",
      "12500 0.0\n",
      "12600 0.0\n",
      "12700 0.0\n",
      "12800 0.0\n",
      "12900 0.0\n",
      "13000 0.0\n",
      "13100 0.0\n",
      "13200 0.0\n",
      "13300 0.0\n",
      "13400 0.0\n",
      "13500 0.0\n",
      "13600 0.0\n",
      "13700 0.0\n",
      "13800 0.0\n",
      "13900 0.0\n",
      "14000 0.0\n",
      "14100 0.0\n",
      "14200 0.0\n",
      "14300 0.0\n",
      "14400 0.0\n",
      "14500 0.0\n",
      "14600 0.0\n",
      "14700 0.0\n",
      "14800 0.0\n",
      "14900 0.0\n",
      "15000 0.0\n",
      "15100 0.0\n",
      "15200 0.0\n",
      "15300 0.0\n",
      "15400 0.0\n",
      "15500 0.0\n",
      "15600 0.0\n",
      "15700 0.0\n",
      "15800 0.0\n",
      "15900 0.0\n",
      "16000 0.0\n",
      "16100 0.0\n",
      "16200 0.0\n",
      "16300 0.0\n",
      "16400 0.0\n",
      "16500 0.0\n",
      "16600 0.0\n",
      "16700 0.0\n",
      "16800 0.0\n",
      "16900 0.0\n",
      "17000 0.0\n",
      "17100 0.0\n",
      "17200 0.0\n",
      "17300 0.0\n",
      "17400 0.0\n",
      "17500 0.0\n",
      "17600 0.0037795305\n",
      "17700 0.0\n",
      "17800 0.0\n",
      "17900 0.0\n",
      "18000 0.0\n",
      "18100 0.013442099\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "for _ in range(1):\n",
    "    for ii in range(0, len(answers), batch_size):\n",
    "        (kb, query, neg_query) = (questions[ii:ii+batch_size], answers[ii:ii+batch_size], wrong_answers[ii:ii+batch_size])\n",
    "        current_loss = model.finetune(kb, query, query, neg_query)\n",
    "        print(ii, current_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions vectorized!\n",
      "Score @1: 0.3915\n",
      "Score @2: 0.5200\n",
      "Score @3: 0.5949\n",
      "Score @4: 0.6493\n",
      "Score @5: 0.6984\n"
     ]
    }
   ],
   "source": [
    "question_vectors = model.predict(df_test['text'].tolist(), type='query')\n",
    "print('questions vectorized!')\n",
    "predictions, gts = ranker(model, question_vectors, df_test, df_doc)\n",
    "for k in range(5):\n",
    "    print('Score @{}: {:.4f}'.format(k+1, scorer(predictions, gts, k+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score @1: 0.3870\n",
      "Score @2: 0.5193\n",
      "Score @3: 0.5896\n",
      "Score @4: 0.6478\n",
      "Score @5: 0.6977\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    print('Score @{}: {:.4f}'.format(k+1, scorer(predictions, gts, k+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained\n",
    "Score @1: 0.3870  \n",
    "Score @2: 0.5193  \n",
    "Score @3: 0.5896  \n",
    "Score @4: 0.6478  \n",
    "Score @5: 0.6977  \n",
    "\n",
    "## Using cosine loss (1 epoch, lr=0.1)\n",
    "Score @1: 0.4067  \n",
    "Score @2: 0.5427  \n",
    "Score @3: 0.6153  \n",
    "Score @4: 0.6667  \n",
    "Score @5: 0.7067  \n",
    "\n",
    "## Using triplet loss (1 epoch, lr=0.1, margin=0.1) no shuffling of data\n",
    "Score @1: 0.3915  \n",
    "Score @2: 0.5200  \n",
    "Score @3: 0.5949  \n",
    "Score @4: 0.6493  \n",
    "Score @5: 0.6984  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
