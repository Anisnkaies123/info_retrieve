{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting GoldenRetriever to TF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. USE-QA in TF2\n",
    "\n",
    "Official code sample for TF2  \n",
    "https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40884   , 0.08877401]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorflow-addons\n",
    "# !pip install tensorflow_text\n",
    "# !pip install --upgrade tensorflow-hub\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "questions = [\"What is your age?\"]\n",
    "responses = [\"I am 20 years old.\", \"good morning\"]\n",
    "response_contexts = [\"I will be 21 next year.\", \"great day.\"]\n",
    "\n",
    "module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/2')\n",
    "\n",
    "question_embeddings = module.signatures['question_encoder'](\n",
    "            tf.constant(questions))\n",
    "response_embeddings = module.signatures['response_encoder'](\n",
    "        input=tf.constant(responses),\n",
    "        context=tf.constant(response_contexts))\n",
    "\n",
    "np.inner(question_embeddings['outputs'], response_embeddings['outputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inference in TF2 model\n",
    "Noticeably, it runs faster than previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timing init\n",
      "model initiated!\n",
      "CPU times: user 14.8 s, sys: 877 ms, total: 15.7 s\n",
      "Wall time: 15.6 s\n",
      "\n",
      "timing ques encoding\n",
      "CPU times: user 2.16 s, sys: 11.6 ms, total: 2.18 s\n",
      "Wall time: 2.15 s\n",
      "\n",
      "timing response encoding\n",
      "CPU times: user 2.38 s, sys: 18.7 ms, total: 2.4 s\n",
      "Wall time: 2.37 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.model import GoldenRetriever\n",
    "print(\"timing init\")\n",
    "%time gr = GoldenRetriever({'learning_rate':0.001, 'beta_1':0.9, 'beta_2':0.999})\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# encode 1 question\n",
    "print(\"timing ques encoding\")\n",
    "%time encoded_ques = gr.predict('How old are you?', type='query')\n",
    "print(\"\")\n",
    "\n",
    "# encode multiple questions\n",
    "encoded_ques = gr.predict(['How old are you?', 'What time is it?'], \n",
    "                          type='query')\n",
    "\n",
    "# one response w context\n",
    "print(\"timing response encoding\")\n",
    "%time encoded_res = gr.predict(\"I am 20 years old.\", context=\"I will be 21 next year.\", type='response')\n",
    "print(\"\")\n",
    "\n",
    "# multiple responses w/0 context\n",
    "encoded_res = gr.predict([\"I am 20 years old.\", \"I love apple cider\"], type='response')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading knowledge bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge base lock and loaded!\n",
      "knowledge base lock and loaded!\n",
      "knowledge base lock and loaded!\n",
      "knowledge base (csv) lock and loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['We are looking for candidates who possess a keen interest in the area of machine learning and data science. We believe that candidates can come from any area of specialisation, and our requirements are as follow:\\ni)   Singaporean with a polytechnic diploma or university degree,\\nii) Proficient in Python or R and iii) Is able to implement Machine Learning Algorithms or have a background in Mathematics / Statistics / Computer Science. \\nBeyond that, demonstrated statistical fundamentals and programming ability will be helpful for the technical tests, but a keen learning attitude will be the most important to carry you through the programme. \\n',\n",
       "  'Candidates can expect to be equipped in some or all of the following skills: data modelling/tuning, data engineering, data product-related software engineering, cloud applications. It ranges between individuals, but candidates can be adequately prepared in fields of data science, engineering and consultancy\\n'],\n",
       " array([[0.31154722],\n",
       "        [0.29154548]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load knowledge bases\n",
    "gr.load_kb(path_to_kb='../data/aiap.txt', is_faq=True, kb_name='aiap')\n",
    "gr.load_kb(path_to_kb='../data/resale_tnc.txt', kb_name='resale_tnc')\n",
    "gr.load_kb(path_to_kb='../data/fund_guide_tnc_full.txt', kb_name='nrf')\n",
    "gr.load_csv_kb(path_to_kb='../data/pdpa.csv', cutoff=196, kb_name='pdpa')\n",
    "\n",
    "# make query\n",
    "gr.make_query('What kind of candidates are you looking for?', top_k=2, kb_name='aiap')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initiated!\n",
      "BEFORE FINETUNING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7117115e+00, -8.8389181e-03, -8.8152960e-02, ...,\n",
      "         3.4359641e-02, -5.6950748e-02,  3.1913319e-03],\n",
      "       [-1.7560545e-02,  1.5315282e+00,  2.8173655e-02, ...,\n",
      "         2.7225253e-03,  1.5698759e-02, -8.1266584e-03],\n",
      "       [-4.7530245e-02,  4.8905790e-02,  1.6913337e+00, ...,\n",
      "        -3.7007492e-02, -3.5331409e-02, -9.1013429e-04],\n",
      "       ...,\n",
      "       [-4.3463507e-03,  1.1113880e-02,  1.0710205e-02, ...,\n",
      "         5.0418127e-02,  3.3716073e-03, -2.2927163e-02],\n",
      "       [ 2.6251100e-02, -5.4154057e-02, -1.5461433e-02, ...,\n",
      "        -8.8774767e-03, -2.9500483e-02,  4.1329965e-02],\n",
      "       [ 1.5746625e-02, -2.4634020e-02, -2.4179602e-02, ...,\n",
      "         1.6309937e-02,  1.0962348e-02, -3.4185573e-02]], dtype=float32)>]\n",
      "\n",
      "CPU times: user 30.6 s, sys: 394 ms, total: 31 s\n",
      "Wall time: 30.8 s\n",
      "AFTER FINETUNING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7126808e+00, -9.4091808e-03, -8.9116685e-02, ...,\n",
      "         3.5325810e-02, -5.5978131e-02,  2.5482415e-03],\n",
      "       [-1.6638305e-02,  1.5305541e+00,  2.7213395e-02, ...,\n",
      "         3.6914686e-03,  1.4721945e-02, -8.9991027e-03],\n",
      "       [-4.8525833e-02,  4.9893256e-02,  1.6923290e+00, ...,\n",
      "        -3.8003378e-02, -3.6324788e-02,  5.0438859e-05],\n",
      "       ...,\n",
      "       [-3.3639586e-03,  1.0171405e-02,  9.7289784e-03, ...,\n",
      "         5.1401224e-02,  4.3482143e-03, -2.3773579e-02],\n",
      "       [ 2.7230211e-02, -5.5103160e-02, -1.6440054e-02, ...,\n",
      "        -7.8965034e-03, -2.8535226e-02,  4.0485241e-02],\n",
      "       [ 1.6693756e-02, -2.3678731e-02, -2.5048146e-02, ...,\n",
      "         1.7109701e-02,  1.1943885e-02, -3.3459641e-02]], dtype=float32)>]\n",
      "model initiated!\n",
      "BEFORE FINETUNING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7117115e+00, -8.8389181e-03, -8.8152960e-02, ...,\n",
      "         3.4359641e-02, -5.6950748e-02,  3.1913319e-03],\n",
      "       [-1.7560545e-02,  1.5315282e+00,  2.8173655e-02, ...,\n",
      "         2.7225253e-03,  1.5698759e-02, -8.1266584e-03],\n",
      "       [-4.7530245e-02,  4.8905790e-02,  1.6913337e+00, ...,\n",
      "        -3.7007492e-02, -3.5331409e-02, -9.1013429e-04],\n",
      "       ...,\n",
      "       [-4.3463507e-03,  1.1113880e-02,  1.0710205e-02, ...,\n",
      "         5.0418127e-02,  3.3716073e-03, -2.2927163e-02],\n",
      "       [ 2.6251100e-02, -5.4154057e-02, -1.5461433e-02, ...,\n",
      "        -8.8774767e-03, -2.9500483e-02,  4.1329965e-02],\n",
      "       [ 1.5746625e-02, -2.4634020e-02, -2.4179602e-02, ...,\n",
      "         1.6309937e-02,  1.0962348e-02, -3.4185573e-02]], dtype=float32)>]\n",
      "\n",
      "CPU times: user 31 s, sys: 153 ms, total: 31.1 s\n",
      "Wall time: 30.8 s\n",
      "AFTER FINETUNING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7107497 , -0.00832472, -0.08719803, ...,  0.03340169,\n",
      "        -0.05791666,  0.00378102],\n",
      "       [-0.01846494,  1.532496  ,  0.02912433, ...,  0.00176116,\n",
      "         0.01666986, -0.00728157],\n",
      "       [-0.04653577,  0.04792145,  1.6903394 , ..., -0.03601265,\n",
      "        -0.0343397 , -0.00186119],\n",
      "       ...,\n",
      "       [-0.00532437,  0.0120428 ,  0.01168678, ...,  0.04943923,\n",
      "         0.00240076, -0.0221125 ],\n",
      "       [ 0.02527715, -0.05321706, -0.01448809, ..., -0.00985374,\n",
      "        -0.0304573 ,  0.04214267],\n",
      "       [ 0.01481203, -0.02557859, -0.02333909, ...,  0.01554884,\n",
      "         0.00998539, -0.03486431]], dtype=float32)>]\n",
      "model initiated!\n",
      "BEFORE FINETUNING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7117115e+00, -8.8389181e-03, -8.8152960e-02, ...,\n",
      "         3.4359641e-02, -5.6950748e-02,  3.1913319e-03],\n",
      "       [-1.7560545e-02,  1.5315282e+00,  2.8173655e-02, ...,\n",
      "         2.7225253e-03,  1.5698759e-02, -8.1266584e-03],\n",
      "       [-4.7530245e-02,  4.8905790e-02,  1.6913337e+00, ...,\n",
      "        -3.7007492e-02, -3.5331409e-02, -9.1013429e-04],\n",
      "       ...,\n",
      "       [-4.3463507e-03,  1.1113880e-02,  1.0710205e-02, ...,\n",
      "         5.0418127e-02,  3.3716073e-03, -2.2927163e-02],\n",
      "       [ 2.6251100e-02, -5.4154057e-02, -1.5461433e-02, ...,\n",
      "        -8.8774767e-03, -2.9500483e-02,  4.1329965e-02],\n",
      "       [ 1.5746625e-02, -2.4634020e-02, -2.4179602e-02, ...,\n",
      "         1.6309937e-02,  1.0962348e-02, -3.4185573e-02]], dtype=float32)>]\n",
      "\n",
      "CPU times: user 31 s, sys: 150 ms, total: 31.2 s\n",
      "Wall time: 30.8 s\n",
      "AFTER FINETUNING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7107409 , -0.00982487, -0.08716331, ...,  0.03336748,\n",
      "        -0.05596463,  0.00417718],\n",
      "       [-0.01656285,  1.5305506 ,  0.0271749 , ...,  0.00372077,\n",
      "         0.01669611, -0.00911968],\n",
      "       [-0.04653395,  0.04988524,  1.6903355 , ..., -0.03600977,\n",
      "        -0.03433891, -0.00190343],\n",
      "       ...,\n",
      "       [-0.00533994,  0.01013662,  0.01170703, ...,  0.04942182,\n",
      "         0.00238939, -0.02193728],\n",
      "       [ 0.02724235, -0.053216  , -0.01645694, ..., -0.00788303,\n",
      "        -0.02851624,  0.04034676],\n",
      "       [ 0.014802  , -0.02368971, -0.0232191 , ...,  0.01547062,\n",
      "         0.00998974, -0.03505354]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Testing loss functions\n",
    "\"\"\"\n",
    "v=['QA/Final/Response_tuning/ResidualHidden_1/dense/kernel']\n",
    "var_finetune=[x for x in gr.embed.variables for vv in v if vv in x.name] #get the weights we want to finetune.\n",
    "\n",
    "\"\"\"\n",
    "1. Cosine loss\n",
    "\"\"\"\n",
    "gr = GoldenRetriever(loss='cosine')\n",
    "\n",
    "print(\"BEFORE FINETUNING\")\n",
    "print(gr.var_finetune)\n",
    "print(\"\")\n",
    "\n",
    "questions = [\"What is your age?\"]\n",
    "responses = [\"I am 20 years old.\", \"good morning\"]\n",
    "response_contexts = [\"I will be 21 next year.\", \"great day.\"]\n",
    "%time gr.finetune(questions, responses, response_contexts, label=[1,0])\n",
    "\n",
    "print(\"AFTER FINETUNING\")\n",
    "print(gr.var_finetune)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "2. Contrastive loss\n",
    "\"\"\"\n",
    "gr = GoldenRetriever(loss='contrastive')\n",
    "\n",
    "print(\"BEFORE FINETUNING\")\n",
    "print(gr.var_finetune)\n",
    "print(\"\")\n",
    "\n",
    "questions = [\"What is your age?\"]\n",
    "responses = [\"I am 20 years old.\", \"good morning\"]\n",
    "response_contexts = [\"I will be 21 next year.\", \"great day.\"]\n",
    "%time gr.finetune(questions, responses, response_contexts, label=[1,0])\n",
    "\n",
    "print(\"AFTER FINETUNING\")\n",
    "print(gr.var_finetune)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3. Triplet loss\n",
    "\"\"\"\n",
    "gr = GoldenRetriever(loss='triplet')\n",
    "\n",
    "print(\"BEFORE FINETUNING\")\n",
    "print(gr.var_finetune)\n",
    "print(\"\")\n",
    "\n",
    "questions = [\"What is your age?\"]\n",
    "responses = [\"The top section of the spine is damaged.\"]\n",
    "response_contexts = [\"Call the nurse.\"]\n",
    "%time gr.finetune(questions, responses, response_contexts, neg_answer = [\"I will be 21 years old.\"], neg_answer_context = [\"Time is running out for the elderly and the young.\"])\n",
    "\n",
    "print(\"AFTER FINETUNING\")\n",
    "print(gr.var_finetune)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last few values in the array has changed, indicating that there is successful tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing Exporting and Restoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinitrinh/anaconda3/envs/gr2/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinitrinh/anaconda3/envs/gr2/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine_tune/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine_tune/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER EXPORTING AND RESTORING\n",
      "[<tf.Variable 'QA/Final/Response_tuning/ResidualHidden_1/AdjustDepth/projection/kernel:0' shape=(1024, 512) dtype=float32, numpy=\n",
      "array([[ 1.7107409 , -0.00982487, -0.08716331, ...,  0.03336748,\n",
      "        -0.05596463,  0.00417718],\n",
      "       [-0.01656285,  1.5305506 ,  0.0271749 , ...,  0.00372077,\n",
      "         0.01669611, -0.00911968],\n",
      "       [-0.04653395,  0.04988524,  1.6903355 , ..., -0.03600977,\n",
      "        -0.03433891, -0.00190343],\n",
      "       ...,\n",
      "       [-0.00533994,  0.01013662,  0.01170703, ...,  0.04942182,\n",
      "         0.00238939, -0.02193728],\n",
      "       [ 0.02724235, -0.053216  , -0.01645694, ..., -0.00788303,\n",
      "        -0.02851624,  0.04034676],\n",
      "       [ 0.014802  , -0.02368971, -0.0232191 , ...,  0.01547062,\n",
      "         0.00998974, -0.03505354]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "gr.export(\"fine_tune\")\n",
    "gr.restore(\"fine_tune\")\n",
    "\n",
    "print(\"AFTER EXPORTING AND RESTORING\")\n",
    "print(gr.var_finetune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded weights are the same post-finetuning weights, suggesting that the exporting and restoring worked fine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
