{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model performance against insurance test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.utils import question_cleaner, display_qn_and_ans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import logging\n",
    "logging.basicConfig(filename='evaluation.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load QA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=Path('./data')\n",
    "df_query = pd.read_csv(datapath/'insuranceQA/V2/InsuranceQA.question.anslabel.raw.100.pool.solr.test.encoded', delimiter='\\t', header=None)\n",
    "df_doc = pd.read_csv(datapath/'insuranceQA/V2/InsuranceQA.label2answer.raw.encoded', delimiter='\\t', header=None)\n",
    "df_ind2word = pd.read_csv(datapath/'insuranceQA/V2/vocabulary', sep='\\t', header=None, quotechar='', quoting=3, keep_default_na=False)\n",
    "dict_ind2word = pd.Series(df_ind2word[1].values,index=df_ind2word[0].values).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract only questions that have answers\n",
    "The dataset has this weird thing where the questions that have no correct answers have random answers in the answer column that does not match the question.\n",
    "Also set the index for df_doc for easy reference with .loc later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2000, removed:677, remainder:1323\n"
     ]
    }
   ],
   "source": [
    "df_query=question_cleaner(df_query)\n",
    "df_doc=df_doc.set_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from tokens to full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medicare-insurance</td>\n",
       "      <td>idx_2363 idx_467 idx_8080 idx_31 idx_9966 idx_...</td>\n",
       "      <td>9128</td>\n",
       "      <td>9128 13322 21601 21471 6442 5412 24861 23536 2...</td>\n",
       "      <td>Will Medicare Pay For Smoking Cessation?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "4  medicare-insurance  idx_2363 idx_467 idx_8080 idx_31 idx_9966 idx_...   \n",
       "\n",
       "      2                                                  3  \\\n",
       "4  9128  9128 13322 21601 21471 6442 5412 24861 23536 2...   \n",
       "\n",
       "                                       text  \n",
       "4  Will Medicare Pay For Smoking Cessation?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_...</td>\n",
       "      <td>Coverage follows the car. Example 1: If you we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1  \\\n",
       "0                                                      \n",
       "1  idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_...   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  Coverage follows the car. Example 1: If you we...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def wordifier(tokes):\n",
    "    return ' '.join([dict_ind2word[ind] for ind in tokes.strip().split(' ')])\n",
    "df_doc['text']=df_doc.apply(lambda x: wordifier(x[1]), axis=1)\n",
    "df_query['text']=df_query.apply(lambda x: wordifier(x[1]), axis=1)\n",
    "display(df_query.head(1))\n",
    "display(df_doc.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question is: Will Medicare Pay For Smoking Cessation?\n",
      "Answer index:  [9128]\n",
      "Answers:  ['Medicare will not pay for smoking cessation products such as nicotine substitutes (Nicorette gum, nicotine patch, etc), and Medicare will not pay for pills that reduce the craving to smoke. But Medicare will pay for up to 8 face-to-face smoking cessation counseling sessions with a qualified Medicare doctor during a 12 month period.']\n"
     ]
    }
   ],
   "source": [
    "display_qn_and_ans(df_query, df_doc, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(model, question_vectors, df_query, df_doc):\n",
    "    predictions=[]\n",
    "    gts=[]\n",
    "    for ii, question_vector in enumerate(question_vectors):\n",
    "        kb=[int(xx) for xx in (df_query[3].iloc[ii]).split(' ')]\n",
    "        gt = [int(xx) for xx in (df_query[2].iloc[ii]).split(' ')]\n",
    "        doc_vectors = model.predict(df_doc.loc[kb]['text'].tolist())\n",
    "        cossim = cosine_similarity(doc_vectors, question_vector.reshape(1, -1))\n",
    "        sortargs=np.flip(cossim.argsort(axis=0))\n",
    "        returnedans = [kb[jj[0]] for jj in sortargs]\n",
    "        predictions.append(returnedans)\n",
    "        gts.append(gt)\n",
    "    return predictions, gts\n",
    "        \n",
    "def scorer(predictions, gts, k=3):\n",
    "    'returns score@k'\n",
    "    score=0\n",
    "    total=0\n",
    "    for gt, prediction in zip(gts, predictions):\n",
    "        if bool(set(gt) & set(prediction[:k])):\n",
    "            score+=1\n",
    "        total+=1\n",
    "    return score/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 08:28:35.181463 140347068307200 deprecation.py:323] From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0913 08:28:50.823433 140347068307200 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0913 08:28:57.575173 140347068307200 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions vectorized!\n",
      "Score @1: 0.3870\n",
      "Score @2: 0.5193\n",
      "Score @3: 0.5896\n",
      "Score @4: 0.6478\n",
      "Score @5: 0.6977\n"
     ]
    }
   ],
   "source": [
    "from src.model import QnaEncoderModel\n",
    "model = QnaEncoderModel()\n",
    "question_vectors = model.predict(df_query['text'].tolist(), type='query')\n",
    "print('questions vectorized!')\n",
    "predictions, gts = ranker(model, question_vectors, df_query, df_doc)\n",
    "for k in range(5):\n",
    "    print('Score @{}: {:.4f}'.format(k+1, scorer(predictions, gts, k+1)))\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 14:48:45.433717 140079693276928 deprecation.py:323] From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0913 14:48:46.988466 140079693276928 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score @1: 0.2509\n",
      "Score @2: 0.3462\n",
      "Score @3: 0.4271\n",
      "Score @4: 0.4807\n",
      "Score @5: 0.5344\n"
     ]
    }
   ],
   "source": [
    "from src.model import USEModel\n",
    "model = USEModel()\n",
    "question_vectors = model.predict(df_query['text'].tolist())\n",
    "predictions, gts = ranker(model, question_vectors, df_query, df_doc)\n",
    "for k in range(5):\n",
    "    print('Score @{}: {:.4f}'.format(k+1, scorer(predictions, gts, k+1)))\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1408(/1417) words with w2v vectors\n",
      "Vocab size : 1408\n",
      "Found 25628(/31486) words with w2v vectors\n",
      "New vocab size : 27036 (added 25628 words)\n",
      "Score @1: 0.0831\n",
      "Score @2: 0.1338\n",
      "Score @3: 0.1814\n",
      "Score @4: 0.2260\n",
      "Score @5: 0.2683\n",
      "CPU times: user 19h 25min 14s, sys: 25min 46s, total: 19h 51min 1s\n",
      "Wall time: 3h 33min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.model import InferSent\n",
    "model = InferSent()\n",
    "model.build_vocab(df_query['text'].tolist())\n",
    "model.update_vocab(df_doc['text'].tolist())\n",
    "question_vectors = model.predict(df_query['text'].tolist())\n",
    "predictions, gts = ranker(model, question_vectors, df_query, df_doc)\n",
    "for k in range(5):\n",
    "    print('Score @{}: {:.4f}'.format(k+1, scorer(predictions, gts, k+1)))\n",
    "    logging.info('Score @{}: {:.4f}'.format(k+1, scorer(predictions, gts, k+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
